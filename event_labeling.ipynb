{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import yfinance as yf\n",
    "from typing import  List"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/zb/_v_3sbq938jftd_b07f5kpfm0000gn/T/ipykernel_65343/4266944872.py:3: FutureWarning: YF.download() has changed argument auto_adjust default to True\n",
      "  apple = yf.download(\"AAPL\", start=\"2020-01-01\", end=\"2025-01-01\")\n",
      "[*********************100%***********************]  1 of 1 completed\n"
     ]
    }
   ],
   "source": [
    "# Download Data\n",
    "\n",
    "apple = yf.download(\"AAPL\", start=\"2020-01-01\", end=\"2025-01-01\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "apple.columns = [\"Close\", \"High\", \"Low\", \"Open\", \"Volume\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Close</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Open</th>\n",
       "      <th>Volume</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2020-01-02</th>\n",
       "      <td>72.468254</td>\n",
       "      <td>72.528574</td>\n",
       "      <td>71.223252</td>\n",
       "      <td>71.476592</td>\n",
       "      <td>135480400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-01-03</th>\n",
       "      <td>71.763725</td>\n",
       "      <td>72.523754</td>\n",
       "      <td>71.539337</td>\n",
       "      <td>71.696167</td>\n",
       "      <td>146322800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-01-06</th>\n",
       "      <td>72.335556</td>\n",
       "      <td>72.374162</td>\n",
       "      <td>70.634539</td>\n",
       "      <td>70.885472</td>\n",
       "      <td>118387200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-01-07</th>\n",
       "      <td>71.995354</td>\n",
       "      <td>72.600960</td>\n",
       "      <td>71.775789</td>\n",
       "      <td>72.345204</td>\n",
       "      <td>108872000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-01-08</th>\n",
       "      <td>73.153496</td>\n",
       "      <td>73.455095</td>\n",
       "      <td>71.698581</td>\n",
       "      <td>71.698581</td>\n",
       "      <td>132079200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-12-24</th>\n",
       "      <td>257.037506</td>\n",
       "      <td>257.047440</td>\n",
       "      <td>254.140589</td>\n",
       "      <td>254.339701</td>\n",
       "      <td>23234700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-12-26</th>\n",
       "      <td>257.853760</td>\n",
       "      <td>258.928914</td>\n",
       "      <td>256.470034</td>\n",
       "      <td>257.027510</td>\n",
       "      <td>27237100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-12-27</th>\n",
       "      <td>254.439224</td>\n",
       "      <td>257.535238</td>\n",
       "      <td>251.920617</td>\n",
       "      <td>256.669129</td>\n",
       "      <td>42355300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-12-30</th>\n",
       "      <td>251.064484</td>\n",
       "      <td>252.358634</td>\n",
       "      <td>249.621015</td>\n",
       "      <td>251.094347</td>\n",
       "      <td>35557500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-12-31</th>\n",
       "      <td>249.292511</td>\n",
       "      <td>252.139635</td>\n",
       "      <td>248.306963</td>\n",
       "      <td>251.303420</td>\n",
       "      <td>39480700</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1258 rows Ã— 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Close        High         Low        Open     Volume\n",
       "Date                                                                 \n",
       "2020-01-02   72.468254   72.528574   71.223252   71.476592  135480400\n",
       "2020-01-03   71.763725   72.523754   71.539337   71.696167  146322800\n",
       "2020-01-06   72.335556   72.374162   70.634539   70.885472  118387200\n",
       "2020-01-07   71.995354   72.600960   71.775789   72.345204  108872000\n",
       "2020-01-08   73.153496   73.455095   71.698581   71.698581  132079200\n",
       "...                ...         ...         ...         ...        ...\n",
       "2024-12-24  257.037506  257.047440  254.140589  254.339701   23234700\n",
       "2024-12-26  257.853760  258.928914  256.470034  257.027510   27237100\n",
       "2024-12-27  254.439224  257.535238  251.920617  256.669129   42355300\n",
       "2024-12-30  251.064484  252.358634  249.621015  251.094347   35557500\n",
       "2024-12-31  249.292511  252.139635  248.306963  251.303420   39480700\n",
       "\n",
       "[1258 rows x 5 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "apple"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Event based labeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "prices = apple[\"Close\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cusum_filter_events_dynamic_threshold(\n",
    "        prices: pd.Series,\n",
    "        threshold: pd.Series\n",
    ") -> pd.DatetimeIndex:\n",
    "    \"\"\"\n",
    "    Detect events using the Symmetric Cumulative Sum (CUSUM) filter.\n",
    "\n",
    "    The Symmetric CUSUM filter is a change-point detection algorithm used to identify events where the price difference\n",
    "    exceeds a predefined threshold.\n",
    "\n",
    "    :param prices: A pandas Series of prices.\n",
    "    :param threshold: A pandas Series containing the predefined threshold values for event detection.\n",
    "    :return: A pandas DatetimeIndex containing timestamps of detected events.\n",
    "\n",
    "    References:\n",
    "    - De Prado, M. (2018) Advances in financial machine learning. John Wiley & Sons. (Methodology: 39)\n",
    "    \"\"\"\n",
    "    time_events, shift_positive, shift_negative = [], 0, 0\n",
    "    price_delta = prices.diff().dropna()\n",
    "    thresholds = threshold.copy()\n",
    "    price_delta, thresholds = price_delta.align(thresholds, join=\"inner\", copy=False)\n",
    "\n",
    "    for (index, value), threshold_ in zip(price_delta.to_dict().items(), thresholds.to_dict().values()):\n",
    "        shift_positive = max(0, shift_positive + value)\n",
    "        shift_negative = min(0, shift_negative + value)\n",
    "\n",
    "        if shift_negative < -threshold_:\n",
    "            shift_negative = 0\n",
    "            time_events.append(index)\n",
    "\n",
    "        elif shift_positive > threshold_:\n",
    "            shift_positive = 0\n",
    "            time_events.append(index)\n",
    "\n",
    "    return pd.DatetimeIndex(time_events)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def daily_volatility_with_log_returns(\n",
    "        close: pd.Series,\n",
    "        span: int = 100\n",
    ") -> pd.Series:\n",
    "    \"\"\"\n",
    "    Calculate the daily volatility at intraday estimation points using Exponentially Weighted Moving Average (EWMA).\n",
    "\n",
    "    :param close: A pandas Series of daily close prices.\n",
    "    :param span: The span parameter for the Exponentially Weighted Moving Average (EWMA).\n",
    "    :return: A pandas Series containing daily volatilities.\n",
    "\n",
    "    References:\n",
    "    - De Prado, M. (2018) Advances in financial machine learning. John Wiley & Sons. (Methodology: Page 44)\n",
    "    \"\"\"\n",
    "    df1 = close.index.searchsorted(close.index - pd.Timedelta(days=1))\n",
    "    df1 = df1[df1 > 0]\n",
    "    df = pd.DataFrame(index=close.index[close.shape[0] - df1.shape[0]:])\n",
    " \n",
    "    df['yesterday'] = close.iloc[df1].values\n",
    "    df['two_days_ago'] = close.iloc[df1 - 1].values\n",
    "    returns = np.log(df['yesterday'] / df['two_days_ago'])\n",
    "    \n",
    "    stds = returns.ewm(span=span).std().rename(\"std\")\n",
    "\n",
    "    return stds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vertical_barrier(\n",
    "    close: pd.Series,\n",
    "    time_events: pd.DatetimeIndex,\n",
    "    number_days: int\n",
    ") -> pd.Series:\n",
    "    \"\"\"\n",
    "    Shows one way to define a vertical barrier.\n",
    "\n",
    "    :param close: A dataframe of prices and dates.\n",
    "    :param time_events: A vector of timestamps.\n",
    "    :param number_days: A number of days for the vertical barrier.\n",
    "    :return: A pandas series with the timestamps of the vertical barriers.\n",
    "    \"\"\"\n",
    "    timestamp_array = close.index.searchsorted(time_events + pd.Timedelta(days=number_days))\n",
    "    timestamp_array = timestamp_array[timestamp_array < close.shape[0]]\n",
    "    timestamp_array = pd.Series(close.index[timestamp_array], index=time_events[:timestamp_array.shape[0]])\n",
    "    return timestamp_array\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def triple_barrier(\n",
    "    close: pd.Series,\n",
    "    events: pd.DataFrame,\n",
    "    profit_taking_stop_loss: list[float, float],\n",
    "    molecule: list\n",
    ") -> pd.DataFrame:\n",
    "    # Filter molecule to ensure all timestamps exist in events\n",
    "    molecule = [m for m in molecule if m in events.index]\n",
    "\n",
    "    # Continue with the existing logic\n",
    "    events_filtered = events.loc[molecule]\n",
    "    output = events_filtered[['End Time']].copy(deep=True)\n",
    "\n",
    "    if profit_taking_stop_loss[0] > 0:\n",
    "        profit_taking = profit_taking_stop_loss[0] * events_filtered['Base Width']\n",
    "    else:\n",
    "        profit_taking = pd.Series(index=events.index)\n",
    "\n",
    "    if profit_taking_stop_loss[1] > 0:\n",
    "        stop_loss = -profit_taking_stop_loss[1] * events_filtered['Base Width']\n",
    "    else:\n",
    "        stop_loss = pd.Series(index=events.index)\n",
    "\n",
    "    for location, timestamp in events_filtered['End Time'].fillna(close.index[-1]).items():\n",
    "        df = close[location:timestamp]\n",
    "        df = np.log(df / close[location]) * events_filtered.at[location, 'Side']\n",
    "        output.loc[location, 'stop_loss'] = df[df < stop_loss[location]].index.min()\n",
    "        output.loc[location, 'profit_taking'] = df[df > profit_taking[location]].index.min()\n",
    "\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def meta_events(\n",
    "    close: pd.Series,\n",
    "    time_events: pd.DatetimeIndex,\n",
    "    ptsl: List[float],\n",
    "    target: pd.Series,\n",
    "    return_min: float,\n",
    "    num_threads: int,\n",
    "    timestamp: pd.Series = False,\n",
    "    side: pd.Series = None\n",
    ") -> pd.DataFrame:\n",
    "    # Filter target by time_events and return_min\n",
    "    target = target.loc[time_events]\n",
    "    target = target[target > return_min]\n",
    "\n",
    "    # Ensure timestamp is correctly initialized\n",
    "    if timestamp is False:\n",
    "        timestamp = pd.Series(pd.NaT, index=time_events)\n",
    "    else:\n",
    "        timestamp = timestamp.loc[time_events]\n",
    "\n",
    "    if side is None:\n",
    "        side_position, profit_loss = pd.Series(1., index=target.index), [ptsl[0], ptsl[0]]\n",
    "    else:\n",
    "        side_position, profit_loss = side.loc[target.index], ptsl[:2]\n",
    "\n",
    "    # Include 'target' and 'timestamp' in the events DataFrame\n",
    "    events = pd.concat({'End Time': timestamp, 'Base Width': target, 'Side': side_position, 'target': target, 'timestamp': timestamp}, axis=1).dropna(subset=['Base Width'])\n",
    "\n",
    "\n",
    "    df0 = list(map(\n",
    "        triple_barrier,\n",
    "        [close] * num_threads,\n",
    "        [events] * num_threads,\n",
    "        [profit_loss] * num_threads,\n",
    "        np.array_split(time_events, num_threads)\n",
    "    ))\n",
    "    df0 = pd.concat(df0, axis=0)\n",
    "\n",
    "    events['End Time'] = df0.dropna(how='all').min(axis=1)\n",
    "\n",
    "    if side is None:\n",
    "        events = events.drop('Side', axis=1)\n",
    "\n",
    "    # Return events including the 'target' and 'timestamp' columns\n",
    "    return events , df0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def meta_labeling(\n",
    "    events: pd.DataFrame,\n",
    "    close: pd.Series\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Expands label to incorporate meta-labeling.\n",
    "\n",
    "    :param events: DataFrame with timestamp of vertical barrier and unit width of the horizontal barriers.\n",
    "    :param close: Series of close prices with date indices.\n",
    "    :return: DataFrame containing the return and binary labels for each event.\n",
    "\n",
    "    Reference:\n",
    "    De Prado, M. (2018) Advances in financial machine learning. John Wiley & Sons.\n",
    "    Methodology: 51\n",
    "    \"\"\"\n",
    "    events_filtered = events.dropna(subset=['End Time'])\n",
    "    all_dates = events_filtered.index.union(events_filtered['End Time'].values).drop_duplicates()\n",
    "    close_filtered = close.reindex(all_dates, method='bfill')\n",
    "    out = pd.DataFrame(index=events_filtered.index)\n",
    "    out['End Time'] = events['End Time']\n",
    "    out['Return of Label'] = close_filtered.loc[events_filtered['End Time'].values].values / close_filtered.loc[events_filtered.index] - 1\n",
    "\n",
    "    if 'Side' in events_filtered:\n",
    "        out['Return of Label'] *= events_filtered['Side']\n",
    "    out['Label'] = np.sign(out['Return of Label'])  * (1 - (events['End Time'] == events['timestamp']))\n",
    "    if 'Side' in events_filtered:\n",
    "        out.loc[out['Return of Label'] <= 0, 'Label'] = 0\n",
    "        out['Side'] = events_filtered['Side']\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "volatility = daily_volatility_with_log_returns(prices, 30)\n",
    "filter_threshold = 1.5\n",
    "moelcules = cusum_filter_events_dynamic_threshold(np.log(prices), filter_threshold * volatility)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
